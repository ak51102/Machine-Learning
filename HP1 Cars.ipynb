{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cars.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/HP1%20Cars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_FNHMBBuaYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use seaborn for pairplot\n",
        "!pip install seaborn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuQfdDw9t0Ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYU6c8pATpJ3",
        "colab_type": "text"
      },
      "source": [
        "#Regression: predict fuel efficiency\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvHVdXuxWhyW",
        "colab_type": "text"
      },
      "source": [
        "### Get the data\n",
        "First download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn5wKbyAuhob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "dataset_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyx-ftElullo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "print(\"done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzTqNJtcGR57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNeh3ZEZ2mCS",
        "colab_type": "text"
      },
      "source": [
        "# **Data Correlation**\n",
        "Can the correlation of the data help improve the model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsoTUvWY2i24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = dataset.corr()\n",
        "sns.heatmap(corr, \n",
        "            xticklabels=corr.columns.values,\n",
        "            yticklabels=corr.columns.values)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YaS1HbKlG2T",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ87-bNLTkaW",
        "colab_type": "text"
      },
      "source": [
        "###Clean the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LamhjvDhuoLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tqqn6VrGnKU",
        "colab_type": "text"
      },
      "source": [
        "For this tutorial:\n",
        "1. You can drop the missing rows<br>\n",
        "2. Use the information at the end of this lab for the missing data values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCmsdAA2urM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.dropna()\n",
        "dataset.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9m3H_3vtr3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRF193U-uGGm",
        "colab_type": "text"
      },
      "source": [
        "You could also look at the number of times each value appears in a column. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0euzNtNt0if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['Cylinders'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80RdCe_cWzsl",
        "colab_type": "text"
      },
      "source": [
        "###Convert categorical data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkRqMVRSuuQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "origin = dataset.pop('Origin')\n",
        "print(\"done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULBG91iUrRkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgd7898Suy-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['USA'] = (origin == 1)*1.0\n",
        "dataset['Europe'] = (origin == 2)*1.0\n",
        "dataset['Japan'] = (origin == 3)*1.0\n",
        "dataset.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKNV0_cYm_GQ",
        "colab_type": "text"
      },
      "source": [
        "###Split the data into train and test sets\n",
        "Now split the dataset into a training set and a test set.\n",
        "\n",
        "We will use the test set in the final evaluation of our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUyZutHEuvqn",
        "colab_type": "text"
      },
      "source": [
        "# **Tune the Test-Training set split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p9qU-wsu12c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0.5 - 0.95\n",
        "train_dataset = dataset.sample(frac=0.5,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "print(\"done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv11n2IJnF2r",
        "colab_type": "text"
      },
      "source": [
        "### Inspect the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_oKhu1_nLML",
        "colab_type": "text"
      },
      "source": [
        "Also look at the overall statistics.<br> The stats for the training set and the test set should be similiar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6l0b9eEu7qJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"MPG\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpogLVNYHrxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_stats = test_dataset.describe()\n",
        "test_stats.pop(\"MPG\")\n",
        "test_stats = test_stats.transpose()\n",
        "test_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRTzQ1vznRDh",
        "colab_type": "text"
      },
      "source": [
        "### Split features from labels\n",
        "\n",
        "Separate the target value, or \"label\", from the features. This label is the value that you will train the model to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J1K03vqu_TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')\n",
        "print(\"done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNQ0oNx3nWto",
        "colab_type": "text"
      },
      "source": [
        "### Normalize the data\n",
        "\n",
        "Look again at the `train_stats` block above and note how different the ranges of each feature are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehaQyUlYu_Vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)\n",
        "print(\"done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr05L9C-nn3X",
        "colab_type": "text"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLXCuq5bI96E",
        "colab_type": "text"
      },
      "source": [
        "# **Define the model**\n",
        "1. Change the number of neurons in the model\n",
        "\n",
        "2. Try different activation functions:\n",
        ">sigmoid<br>\n",
        "tanh<br>\n",
        "relu<br>\n",
        "leaky_relu<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuifNbWBvE86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import metrics\n",
        "\n",
        "inputs = len(train_dataset.keys())\n",
        "print(\"number of inputs to the model = \" + str(inputs))\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    #Change the number of neurons\n",
        "    #Change the activation function                      \n",
        "    layers.Dense(12, activation=tf.nn.sigmoid,input_shape=([len(train_dataset.keys())]),),\n",
        "    layers.Dense(12, activation=tf.nn.sigmoid),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mean_squared_error', \n",
        "                optimizer=optimizer,\n",
        "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "  return model\n",
        "  print(\"done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuLqDLYVnse_",
        "colab_type": "text"
      },
      "source": [
        "### Build the model\n",
        "\n",
        "Let's build our model. Here, we'll use a `Sequential` model with two densely connected hidden layers, and an output layer that returns a single, continuous value. The model building steps are wrapped in a function, `build_model`, since we'll create a second model, later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AWO9qoivE-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "print(\"done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgG_jimRvJs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70CAspBBoL3K",
        "colab_type": "text"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "Train the model and record the training and validation accuracy in the `history` object.\n",
        "\n",
        "ML Vocabulary: https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC2qUqN_impr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbjeiXNqoQlL",
        "colab_type": "text"
      },
      "source": [
        "# **Train the model**<br>\n",
        "The number of epochs is set by the early stopping, so there is no need to tune it. <br>\n",
        "\n",
        "<br>\n",
        "But you will want to tune the batch_size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK0vc8KtvnXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 1000\n",
        "model = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,batch_size=2,\n",
        "                    validation_split = 0.2, verbose=0, callbacks=[early_stop])\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZEgJYfCvna3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=1)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Iohx0ppoz2Y",
        "colab_type": "text"
      },
      "source": [
        "### Test the model\n",
        "\n",
        "Finally, predict MPG values using data in the testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgxftPkGvyhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNJSROOHothN",
        "colab_type": "text"
      },
      "source": [
        "Add the missing data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8OQJCAaopzt",
        "colab_type": "text"
      },
      "source": [
        "1971 Ford Pinto<br>\n",
        "dataset.at[32,\"Horsepower\"] = 100<br>\n",
        "print(dataset.loc[32])<br>\n",
        "\n",
        "1974 Ford Maverick<br>\n",
        "dataset.at[126,\"Horsepower\"] = 75<br>\n",
        "print(dataset.loc[126])<br>\n",
        "\n",
        "1980 Renault Le Car De Luxe<br>\n",
        "dataset.at[330,\"Horsepower\"] = 50<br>\n",
        "print(dataset.loc[330])<br>\n",
        "\n",
        "1980 Ford Mustang Cobra<br>\n",
        "dataset.at[336,\"Horsepower\"] = 88<br>\n",
        "print(dataset.loc[336])<br>\n",
        "\n",
        "1981 Renault 18i<br>\n",
        "dataset.at[354,\"Horsepower\"] = 81<br>\n",
        "print(dataset.loc[354])br>\n",
        "1982 AMC Concord DL<br>\n",
        "dataset.at[374,\"Horsepower\"] = 82<br>\n",
        "print(dataset.loc[374])"
      ]
    }
  ]
}